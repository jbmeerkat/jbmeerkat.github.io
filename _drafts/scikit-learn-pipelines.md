---
layout: post
title: 'Конвейеры (pipelines) в scikit-learn: примеры использования'
categories: machine-learning
tags: machine-learning scikit-learn pipelines
---

__План:__
- ~~Для чего нужны конвейеры~~
- ~~Что могут делать~~
- ~~Какие типы шагов существуют~~
- ~~Интерфейс шагов и конвейера~~
- ~~Данные для примера~~
- Решение задач с помощью конвейера
  - Разделение на обучение/тест/валидацию
  - Стандартизация/масштабирование признаков
  - Удаление пропусков
  - Кодирование разных типов признаков (категориальные/численные)
  - Отбор признаков
  - Обучение модели
  - Получение оценок/метрик/прогноза
- Полноценный пример конвейера со всеми этими шагами максимально приближенный к реальной жизни

_Отметить момент с порядком разбиения и масштабирование/стандартизацией https://machinelearningmastery.com/data-preparation-without-data-leakage_

__TL; DR__ делаем полноценный pipeline на ~реальном~ максимально приближенном к реальности наборе данных с
подготовкой признаков, отбором, масштабированием, обучением и оценкой.

__Оглавление__
- [Цель статьи](#why)
- [Терминология](#terminology)
- [Для чего нужен pipeline](#purpose)
- [Какие шаги есть в pipeline](#steps)
- [Типичные задачи](#typical-tasks)
  - [Преобразование данных](#easy-transforming)
  - [Преобразование данных и обучение модели](#fit-transform)
  - [Преобразование данных, обучение и предсказание](#fit-predict)
  - [Преобразование, обучение, предсказание и оценка](#score)
  - [Преоразование данных своим алгоритмом](#custom-transformer)
    - [Простой случай (FunctionTransformer)](#function-transformer)
    - [Случай посложнее (TransformerMixin)](#transformer-mixin)
    - [Если непонятно что выбрать — жми сюда](#custom-transformer)
- [Интерфейс шагов и pipeline](#interfaces)
- [Данные](#data)


## <a name="why"></a>Цель статьи

На русском нет хороших, понятных статей с близкими к реальной жизни примерами. Да и на английском все не очень. Есть
[официальная документация](https://scikit-learn.org/stable/modules/compose.html#pipeline), но она на английском и там не цельный пример, а
разрозненные части.


## <a name="terminology"></a>Терминология

В русском сообществе машинного обучения как только не говорят, но чаще всего используют прямые заимствования
английских терминов: пайплайн, трансформер, эстиматор (это которые estimator из scikit-learn). Хороших устоявшихся
русских терминов я не знаю и поэтому буду использовать исходные термины: pipeline, transformer, estimator.

_Хотя "конвейер" и "преобразователь" вполне неплохи, вот "оценщик" так себе._


## <a name="purpose"></a>Для чего нужен pipeline

Обычно приходится делать похожие вещи: подготовка признаков, отбор, нормализация, обучение, оценка. Pipeline
помогает объединить эти шаги в понятную и удобную структуру, которую можно использовать, например, в
перекрестной проверке (cross-validation) или подборе параметров (например, grid search).

Ещё pipeline может кешировать результаты вычисления промежуточных шагов за счет этого сильно ускоряя
работу при множественных запусках.

Да и если приходилось когда-нибудь страдать от того, что в какой-то момент код так раскидан по тетрадке, что любое
изменение становится болью, а перезапуск всей тетрадки приводит к ошибкам — pipeline может помочь (но это не точно).


## <a name="steps"></a>Какие шаги есть в pipeline

Все промежуточные шаги обязательно должны быть пребразованиями (transformer), последний может быть estimator (про это позже),
например, классификатор или линейная регрессия.

## <a name="typical-tasks"></a>Типичные задачи
Дальше будут описаны все основные сценарии использования pipeline на примере [наших данных](#data).

### <a name="easy-transforming"></a>Преобразование данных существующими компонентами
Будем делать подготовку признаков, отбор и масштабирование.

### <a name="fit-transform"></a>Преобразование данных и обучение модели

### <a name="fit-predict"></a>Преобразование данных, обучение и предсказание

### <a name="score"></a>Преобразование, обучение, предсказание и оценка

### <a name="custom-transformer"></a>Преоразование данных своим алгоритмом
Если вдруг нужного преобразования нет в scikit-learn, то можно сделать свое. Варианта два: написать и использовать
свою функцию или написать свой компонент (класс). Принципиальная разница только в организации кода. Выбирать
вариант предлагаю по такому принципу: мало кода — функция, много кода — класс.

#### <a name="function-transformer"></a>Простой случай (FunctionTransformer)

#### <a name="transformer-mixin"></a>Случай посложнее (TransformerMixin)



## <a name="interfaces"></a>Интерфейс шагов и pipeline

Итого, действующих лиц у нас может быть два (если нужно только преобразовать данные) или три (если нужно обучение):
- Pipeline
- Transformer (произвольное количество)
- Estimator (один, опционально)

_[Официальная документация про transformer и estimator](https://scikit-learn.org/stable/developers/develop.html#different-objects)_

Начнем с pipeline, так как то, что мы от него хотим отчасти определяет интерфейс остальных компонентов.

__Pipeline__ — у него достаточно обширный интерфейс ([документация, подзагловок Methods](https://scikit-learn.org/1.0/modules/generated/sklearn.pipeline.Pipeline.html)),
но в простом случае нас интересует `transform` и `fit`, `predict` и их комбинации: `fit_transform` и `fit_predict`. О них будет дальше.

__Transformer__ — это объект, у которого есть методы `fit` и `transform`.

__Estimator__ — объект, у которого есть метод `fit`.

Что будет происходить когда мы вызываем методы pipeline:
- `fit` — на всех шагах по очереди будут вызваны методы `fit` и `transform`, на последнем шаге будет вызван только `fit` (подразумевается, что там estimator).
- `transform` — на всех шагах по очереди будет вызван метод `transform`. Если последним шагом будет estimator, то ничего не заработает, ведь у него нет метода `transform`.
- `fit_transform` — на всех шагах __включая последний__ по очереди будут вызваны методы `fit` и `transform`. Если последний estimator, то не заработает — нет `transform`.
- `fit_predict` — на всех шагах вызовет `fit` и `transform`, на последнем `fit_predict`.щ

Резюмируя вышенаписанное: если хочется pipeline только для трансформивания данных, то делаем его из transformer и
используем методы `transform` или `fit_transform`; если хочется в конце модель, то ставим в конце ее и вызываем у pipeline `fit`
или `fit_predict`.


## <a name="data"></a>Данные

Пора взяться за дело и начать работать с данными. Сделаем специальный набор данных похожий на реальный.

{% highlight python %}
from random import randint

import pandas as pd
from sklearn import datasets, preprocessing

# У нас будет пять признаков из которых два избыточные, их мы будем позже отфильтровывать.
# Перемешивание отключено, чтобы было понятно какие из признаков нормальные, а какие избыточные,
# чтобы потом взять один из нормальных и сделать из него категориальный
X, y = datasets.make_classification(n_samples=500, n_features=5, n_informative=3, n_redundant=2, shuffle=False)
X = pd.DataFrame(X, columns=['feature0', 'feature1', 'feature2', 'feature3', 'feature4'])
y = pd.Series(y, name='target')


# Сделаем из одного из признаков категориальный
binarizer = preprocessing.KBinsDiscretizer(n_bins=4, encode='ordinal').fit(X[['feature2']])
X.feature2 = binarizer.transform(X[['feature2']])
# Преобразуем числа в строковые метки, чтобы было потом что кодировать обратно
X.feature2.replace({0: 'a', 1: 'b', 2: 'c', 3: 'd'}, inplace=True)


# Добавим пропусков в случайных местах
for i in range(20):
    row_index = randint(0, 499)
    column_index = randint(0, 4)
    X.iloc[row_index, column_index] = None

# Готово! Данные будут выглядеть примерно так
X.head()
   feature0  feature1 feature2  feature3  feature4
0 -2.136315 -2.423877        c  1.204774 -0.784722
1 -0.632453 -0.037067        b  0.483529  0.077790
2 -0.322830 -0.282347        c  0.270344  0.368485
3 -2.358212 -1.735549        d  1.188847 -2.392307
4 -0.669410 -0.506669        a  0.676527  1.425679
{% endhighlight %}
